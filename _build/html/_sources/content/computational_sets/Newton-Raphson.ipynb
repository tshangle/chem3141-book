{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5268e8a7-23c3-49f3-8a17-a109414657d8",
   "metadata": {},
   "source": [
    "# üß≠ Guided Exercise: Newton‚ÄìRaphson Step for a Quadratic Function\n",
    "\n",
    "Let‚Äôs consider the function:\n",
    "\n",
    "$$\n",
    "f(x) = (x - 2)^2 - 2 = x^2 - 4x + 2\n",
    "$$\n",
    "\n",
    "This function has a stationary point at $ x_s = 2 $.  In the language of geometry optimization, this would be an equilibrium geometry.\n",
    "\n",
    "We‚Äôll start at an initial guess $ x_0 = 0 $ and see how the **Newton‚ÄìRaphson method** finds the optimal step toward the stationary point.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úèÔ∏è Step 1: Define the function and its derivatives\n",
    "\n",
    "Using the expressions given:\n",
    "\n",
    "$$\n",
    "f(x) = x^2 - 4x + 2, \\quad\n",
    "f'(x) = 2x - 4, \\quad\n",
    "f''(x) = 2\n",
    "$$\n",
    "\n",
    "üëâ **Your task:** Complete the functions below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0909110-5fcc-4bcf-8fe1-5741aa6991ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define f(x), f'(x), and f''(x)\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Return f(x) = x^2 - 4x + 2\"\"\"\n",
    "    f_x = ### complete with appropriate code\n",
    "    return f_x\n",
    "\n",
    "def fprime(x):\n",
    "    \"\"\"Return the first derivative f'(x) = 2x - 4\"\"\"\n",
    "    fp_x = ### complete with appropriate code\n",
    "    return fp_x \n",
    "\n",
    "def fdoubleprime(x):\n",
    "    \"\"\"Return the second derivative f''(x) = 2\"\"\"\n",
    "    fpp_x = ### complete with appropriate code\n",
    "    return fpp_x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347db503-89d3-4cce-9df6-96ec3b677dfa",
   "metadata": {},
   "source": [
    "## üîç Step 2: Evaluate at the initial point\n",
    "\n",
    "We‚Äôll start from $ x_0 = 0 $.\n",
    "\n",
    "üëâ **Your task:** Evaluate $ f(x_0) $, $ f'(x_0) $, and $ f''(x_0) $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df24352-9547-483c-9364-c5a7bd396d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1.0\n",
    "\n",
    "# TODO: Compute f(x0), f'(x0), f''(x0)\n",
    "f_x0 = # complete with appropriate function call\n",
    "fp_x0 = # complete with appropriate function call\n",
    "fpp_x0 =  # complete with appropriate function call\n",
    "\n",
    "print(f\"f({x0}) = {f_x0}\")\n",
    "print(f\"f'({x0}) = {fp_x0}\")\n",
    "print(f\"f''({x0}) = {fpp_x0}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de456f3-1106-4580-8a65-7683181c840b",
   "metadata": {},
   "source": [
    "## üßÆ Step 3: Find the optimal step\n",
    "\n",
    "From the Taylor expansion, we know the Newton‚ÄìRaphson step is:\n",
    "\n",
    "$$\n",
    "\\Delta x = -\\frac{f'(x_0)}{f''(x_0)}\n",
    "$$\n",
    "\n",
    "üëâ **Your task:** Compute $\\Delta x $ and the updated point $ x_1 = x_0 + \\Delta x $.\n",
    "Do this by hand first and then complete the following code to do the computation with python.  Compare your answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cceab1-9975-4c1d-8516-70098859364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the Newton‚ÄìRaphson step\n",
    "dx = -fp_x0 / fpp_x0\n",
    "x1 = x0 + dx\n",
    "\n",
    "print(f\"Newton-Raphson step Œîx = {dx}\")\n",
    "print(f\"Updated point x1 = {x1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1489c2e4-59fc-48f8-bedc-31ef330eabc2",
   "metadata": {},
   "source": [
    "‚úÖ **Question:** Does $ x_1 $ match the true stationary point $ x_s = 2 $?  \n",
    "\n",
    "---\n",
    "\n",
    "## üí° Discussion\n",
    "\n",
    "Because our function is perfectly quadratic, the Newton‚ÄìRaphson step finds the stationary point **in a single iteration**.  \n",
    "\n",
    "In later examples, we‚Äôll see what happens when $ f(x) $ isn‚Äôt purely quadratic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30201dc1-a980-4407-8a96-b2b8499fae61",
   "metadata": {},
   "source": [
    "# üé® Step 4: Visualizing the Newton‚ÄìRaphson Step\n",
    "\n",
    "Now that we‚Äôve computed the step $ \\Delta x $, let‚Äôs visualize what‚Äôs happening.\n",
    "\n",
    "We‚Äôll plot the function $ f(x) = x^2 - 4x + 2 $, mark the initial point $ x_0 $, and show the tangent line scaled by the inverse of the second derivative at that point.\n",
    "\n",
    "The Newton‚ÄìRaphson step moves from $ x_0 $ to the point where this scaled tangent crosses the $ x $-axix. For this quadratic case, this lands exactly on the stationary point $ x_s = 2 $.\n",
    "\n",
    "---\n",
    "\n",
    "üëâ Run the cell below to see this plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e33a06e-a73b-4ccf-8c78-a7727fc970b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define range of x values for plotting\n",
    "x = np.linspace(-1, 4, 200)\n",
    "\n",
    "# Compute function and tangent line values\n",
    "y = f(x)\n",
    "\n",
    "# Tangent line at x0:\n",
    "# f(x_tangent) = f(x0) + f'(x0)*(x_tangent - x0)\n",
    "y_tangent = f_x0 + fp_x0 / fpp_x0 * (x - x0)\n",
    "\n",
    "# TODO: Create the plot showing f(x), tangent line, and key points\n",
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "# Plot the function\n",
    "plt.plot(x, y, label=r\"$f(x) = x^2 - 4x + 2$\")\n",
    "\n",
    "# Plot the tangent line\n",
    "plt.plot(x, y_tangent, '--', label=\"Tangent scaled by 1 / f''(x_0) at $x_0$\")\n",
    "\n",
    "# Mark the initial point\n",
    "plt.scatter(x0, f_x0, color='red', zorder=3, label=r\"$x_0$\")\n",
    "\n",
    "# Mark the stationary point\n",
    "plt.scatter(x1, f(x1), color='green', zorder=3, label=r\"$x_1$ (stationary point)\")\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Newton‚ÄìRaphson Step for a Quadratic Function\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45ffd0d-7fa2-4b6a-a346-a1303dc16e93",
   "metadata": {},
   "source": [
    "# üöÄ Guided Exercise: Newton‚ÄìRaphson Method for a Non-Quadratic Function\n",
    "\n",
    "In the previous example, we saw that Newton‚ÄìRaphson reached the stationary point of a *quadratic* function in **one step** ‚Äî because the function‚Äôs curvature was constant.\n",
    "\n",
    "Now, let‚Äôs consider a function that **is not exactly quadratic**:\n",
    "\n",
    "$$\n",
    "f(x) = x^3 + x^2 - 5\n",
    "$$\n",
    "\n",
    "The stationary points are at $ x_s = 0 $ and $ x_s = -\\tfrac{2}{3} $,  \n",
    "but imagine we don‚Äôt know these ahead of time.  \n",
    "\n",
    "We‚Äôll start from an initial guess $ x_0 = 1 $ and try to find the stationary point iteratively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82f3f4-f29c-4a8c-8242-4f468682f2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the new function and its derivatives\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Return f(x) = x^3 + x^2 - 5\"\"\"\n",
    "    return x**3 + x**2 - 5\n",
    "\n",
    "def fprime(x):\n",
    "    \"\"\"Return f'(x) = 3x^2 + 2x\"\"\"\n",
    "    return 3*x**2 + 2*x\n",
    "\n",
    "def fdoubleprime(x):\n",
    "    \"\"\"Return f''(x) = 6x + 2\"\"\"\n",
    "    return 6*x + 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f324e2-1692-4605-87bc-93e5efb35602",
   "metadata": {},
   "source": [
    "## üîÅ Step 1: Compute the Newton‚ÄìRaphson update\n",
    "\n",
    "The update rule for finding stationary points is:\n",
    "\n",
    "$$\n",
    "x_{n+1} = x_n - \\frac{f'(x_n)}{f''(x_n)}\n",
    "$$\n",
    "\n",
    "üëâ **Your task:** Implement one iteration of the Newton‚ÄìRaphson step starting from $ x_0 = 1 $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac1f97-828c-4b4e-9e34-435a9f5d1a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 1.0\n",
    "\n",
    "# Compute one iteration\n",
    "x1 = # complete code with appropriate update\n",
    "\n",
    "print(f\"x0 = {x0:.4f}\")\n",
    "print(f\"x1 = {x1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e57db5-23ca-4eb1-a69f-59f0cde71543",
   "metadata": {},
   "source": [
    "‚úÖ **Question:**  \n",
    "How close is your updated value $ x_1$ to one of the true stationary points ($ x_s = 0 $ or $ x_s = -2/3 $)?\n",
    "\n",
    "You should notice that one iteration isn‚Äôt enough this time because the function is *not quadratic*, so the curvature changes with $ x $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64c475-10d4-4c35-9382-01d506cf86be",
   "metadata": {},
   "source": [
    "## üîÑ Step 2: Iterate until convergence\n",
    "\n",
    "üëâ **Your task:** Write a small loop to perform several Newton‚ÄìRaphson iterations.\n",
    "\n",
    "Stop when the change between iterations $|x_{n+1} - x_n|$ becomes very small (e.g. less than $10^{-6}$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec49ac-cbed-4942-b238-fd5b8cc32d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement an iterative Newton‚ÄìRaphson loop\n",
    "\n",
    "x = 1.0\n",
    "tol = 1e-6\n",
    "max_iter = 20\n",
    "\n",
    "for i in range(max_iter):\n",
    "    x_new = # complete with appropriate update to the variable x_new\n",
    "    print(f\"Iteration {i:2d}: x = {x:.6f}\")\n",
    "    if abs(x_new - x) < tol:\n",
    "        print(f\"Converged to stationary point at x = {x_new:.6f}\")\n",
    "        break\n",
    "    x = x_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8d520-0cbc-43fc-b24d-9aebf70b9343",
   "metadata": {},
   "source": [
    "# üß≠ Guided Exercise: Newton‚ÄìRaphson Method in Two Dimensions\n",
    "\n",
    "In one dimension, we wrote the Newton‚ÄìRaphson update for finding a stationary point as\n",
    "\n",
    "$$\n",
    "x_{n+1} = x_n - \\frac{f'(x_n)}{f''(x_n)}.\n",
    "$$\n",
    "\n",
    "In **two dimensions (and higher)**, this generalizes to:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_{n+1} = \\mathbf{x}_n - \\mathbf{H}^{-1}(\\mathbf{x}_n) \\, \\nabla f(\\mathbf{x}_n)\n",
    "$$\n",
    "\n",
    "where  \n",
    "- $ \\nabla f(\\mathbf{x}) $ is the **gradient vector**, and  \n",
    "- $ \\mathbf{H}(\\mathbf{x}) $ is the **Hessian matrix** (matrix of second derivatives).\n",
    "\n",
    "We‚Äôll begin with a **perfectly quadratic function** where Newton‚Äôs method finds the minimum in a single step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92cd9aa-bb3f-4f81-81e4-8400684745a6",
   "metadata": {},
   "source": [
    "## ‚úèÔ∏è Step 1: Perfectly Quadratic 2D Function\n",
    "\n",
    "Let‚Äôs consider\n",
    "\n",
    "$\n",
    "f(x, y) = (x - 1)^2 + 2(y - 2)^2.\n",
    "$\n",
    "\n",
    "This function has its stationary point (and minimum) at $ (x_s, y_s) = (1, 2) $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4110328-9387-4c91-9072-f299f04defd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the function, gradient, and Hessian\n",
    "def f(x, y):\n",
    "    fxy = ### Complete with 2D function computing (x-1)^2 + 2(y-2)^2\n",
    "    return fxy\n",
    "\n",
    "def grad_f(x, y):\n",
    "    \"\"\"Gradient vector ‚àáf = [‚àÇf/‚àÇx, ‚àÇf/‚àÇy]\"\"\"\n",
    "    dfdx = ### complete with partial first derivative of f(x,y) wrt x\n",
    "    dfdy = ### complete with partial first derivative of f(x,y) wrt y\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "def hessian_f(x, y):\n",
    "    \"\"\"Hessian matrix H = [[‚àÇ¬≤f/‚àÇx¬≤, ‚àÇ¬≤f/‚àÇx‚àÇy], [‚àÇ¬≤f/‚àÇy‚àÇx, ‚àÇ¬≤f/‚àÇy¬≤]]\"\"\"\n",
    "    d2fx2 = ### complete with ‚àÇ¬≤f/‚àÇx¬≤\n",
    "    d2fxy = ### complete with ‚àÇ¬≤f/‚àÇx‚àÇy\n",
    "    d2fyx = ### complete with ‚àÇ¬≤f/‚àÇy‚àÇx\n",
    "    d2fy2 = ### complete with ‚àÇ¬≤f/‚àÇy¬≤\n",
    "    \n",
    "    return np.array([[d2fx2, d2fxy],\n",
    "                     [d2fyx, d2fy2]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11509332-75a7-4656-a867-cfd93f04904d",
   "metadata": {},
   "source": [
    "## üîÅ Step 2: Perform one Newton‚ÄìRaphson step\n",
    "\n",
    "Start from an initial point $\\mathbf{x}_0 = (0, 0) $ and compute one Newton update:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_1 = \\mathbf{x}_0 - \\mathbf{H}^{-1}(\\mathbf{x}_0) \\nabla f(\\mathbf{x}_0)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88b4d9-b1ec-428b-bd60-f24afba7f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy0 = np.array([0.0, 0.0])\n",
    "\n",
    "# Compute gradient and Hessian\n",
    "g = ## call function to compute grad of f(x,y) at point given by xy0 \n",
    "H = ## call function to compute Hessian of f(x,y) at point given by xy0\n",
    "\n",
    "# Newton update\n",
    "x1 = xy0 - np.linalg.inv(H) @ g\n",
    "\n",
    "print(\"x0 =\", xy0)\n",
    "print(\"Gradient =\", g)\n",
    "print(\"x1 =\", x1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdbf4c8-1364-4e42-a974-91460157e87a",
   "metadata": {},
   "source": [
    "‚úÖ **Question:**  \n",
    "Does your single update step land exactly on the stationary point $ (1, 2) $?  \n",
    "Why does it only take one step for this function?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e954b1-6c1f-4050-8359-34db80879d26",
   "metadata": {},
   "source": [
    "# üåä Step 3: Newton‚ÄìRaphson on a Non-Quadratic 2D Function\n",
    "\n",
    "Now let‚Äôs consider a *non-quadratic* function, where the curvature changes with position:\n",
    "\n",
    "$$\n",
    "f(x, y) = \\sin(x) + \\cos(y)\n",
    "$$\n",
    "\n",
    "This function has stationary points where both partial derivatives vanish:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x} = \\cos(x) = 0, \\quad \\frac{\\partial f}{\\partial y} = -\\sin(y) = 0.\n",
    "$$\n",
    "\n",
    "That means stationary points occur when $ x = \\pi/2 + n\\pi $ and $ y = n\\pi $.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317979c7-8188-47ef-9077-a7c2dfb5c47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function, gradient, and Hessian for the sinusoidal surface\n",
    "def f2(x, y):\n",
    "    fxy = ### complete with f(x,y) = sin(x) + cos(y)\n",
    "    return fxy\n",
    "\n",
    "def grad_f2(x, y):\n",
    "    dfdx = ### complete with dfdx\n",
    "    dfdy = ### complete with dfdy\n",
    "    return np.array([dfdx, dfdy])\n",
    "\n",
    "def hessian_f2(x, y):\n",
    "    d2fx2 = ### complete with ‚àÇ¬≤f/‚àÇx¬≤\n",
    "    d2fxy = ### complete with ‚àÇ¬≤f/‚àÇx‚àÇy\n",
    "    d2fyx = ### complete with ‚àÇ¬≤f/‚àÇy‚àÇx\n",
    "    d2fy2 = ### complete with ‚àÇ¬≤f/‚àÇy¬≤\n",
    "    \n",
    "    return np.array([[d2fx2, d2fxy],\n",
    "                     [d2fyx, d2fy2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528ec2a5-15a0-47d0-840e-e32112530df3",
   "metadata": {},
   "source": [
    "## üîÑ Step 4: Iterate Newton‚ÄìRaphson updates\n",
    "\n",
    "The next block will put these updated functions for $f(x,y) = {\\rm sin}(x) + {\\rm cos}(y)$ starting from $ (x_0, y_0) = (2, 1) $ and apply a few Newton steps to find a nearby stationary point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8943feb7-3b18-4601-bc9c-edcb530333f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = np.array([2.0, 1.0])\n",
    "tol = 1e-6\n",
    "max_iter = 10\n",
    "\n",
    "for i in range(max_iter):\n",
    "    g = grad_f2(*x)\n",
    "    H = hessian_f2(*x)\n",
    "    step = np.linalg.solve(H, g)  # equivalent to inv(H) @ g but more stable\n",
    "    x_new = x - step\n",
    "    print(f\"Iter {i:2d}: x = {x}, f(x) = {f2(*x):.4f}\")\n",
    "    if np.linalg.norm(x_new - x) < tol:\n",
    "        print(f\"Converged to stationary point: {x_new}\")\n",
    "        break\n",
    "    x = x_new\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7615e4-5434-44e6-8663-c099fc09dca8",
   "metadata": {},
   "source": [
    "‚úÖ **Questions:**\n",
    "1. Which stationary point does the iteration converge to?  \n",
    "2. What happens if you start from a different initial guess ‚Äî e.g. $ (x_0, y_0) = (0, 0) $?  \n",
    "3. Does the algorithm always converge to a minimum, or can it find a maximum or saddle point?\n",
    "\n",
    "---\n",
    "\n",
    "üí° **Discussion**\n",
    "\n",
    "In 2D, the Newton‚ÄìRaphson method uses the **Hessian matrix** to locally approximate the curvature in all directions.  \n",
    "If the Hessian is positive definite, you‚Äôre near a **minimum**;  \n",
    "if it‚Äôs negative definite, you‚Äôre near a **maximum**;  \n",
    "and if it has both positive and negative eigenvalues, you‚Äôve found a **saddle point**.\n",
    "\n",
    "---\n",
    "\n",
    "üéØ **Challenge Extension**\n",
    "\n",
    "Implement a general function `newton_2d(f, grad_f, hessian_f, x0, tol, max_iter)`  \n",
    "that performs these updates automatically and returns:\n",
    "- the final point,\n",
    "- the number of iterations, and\n",
    "- the trajectory of points for visualization.\n",
    "\n",
    "(You can, in principle, then plot the path of iterations on a contour plot of $ f(x, y) $!)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059157c-1961-4b35-8237-94b4402b7947",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Step 5: Finite-Difference Gradients and Hessians\n",
    "\n",
    "So far, we‚Äôve relied on **analytical derivatives** ‚Äî but in many real problems,  \n",
    "we can‚Äôt easily compute $ \\nabla f$ or $ \\mathbf{H} $ analytically.\n",
    "\n",
    "A common alternative is to use **finite differences**:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x_i} \\approx \\frac{f(x_i + h) - f(x_i - h)}{2h}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 f}{\\partial x_i \\partial x_j} \\approx\n",
    "\\frac{f(x_i + h, x_j + h) - f(x_i + h, x_j - h)\n",
    "- f(x_i - h, x_j + h) + f(x_i - h, x_j - h)}{4h^2}.\n",
    "$$\n",
    "\n",
    "where $h$ is some small step along the direction $x_i$ or $x_j$, as appropriate.  This finite difference approximation typically becomes closer to the exact derivative as $h$ approaches zero, so numerically we typically set $h$ to some very small value like $h = 0.001$ Angstroms for molecular geometries. \n",
    "\n",
    "We‚Äôll test this idea using the same function:\n",
    "\n",
    "$$\n",
    "f(x, y) = \\sin(x) + \\cos(y)\n",
    "$$\n",
    "\n",
    "and compare our **numerical** gradients and Hessians to the **analytical** ones.  Again, it will be adequate to set $h$ to some very small value like $h = 0.001$ for this comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49e3b92-837f-422f-9b37-2ed31ce6fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numerical_grad(f, x, h=1e-3):\n",
    "    \"\"\"\n",
    "    Compute the numerical gradient (‚àáf) of a 2D function using central finite differences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        A Python function that takes two arguments, e.g. f(x, y) = sin(x) + cos(y).\n",
    "    x : array-like of shape (2,)\n",
    "        The point [x, y] at which to evaluate the gradient.\n",
    "    h : float, optional\n",
    "        The finite difference step size (default is 1e-3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grad : ndarray of shape (2,)\n",
    "        The numerical gradient vector [‚àÇf/‚àÇx, ‚àÇf/‚àÇy].\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize gradient vector with zeros (same dimension as x)\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    # Loop over each coordinate direction (x and y)\n",
    "    for i in range(len(x)):\n",
    "        # Create a step vector for perturbing one coordinate at a time\n",
    "        step = np.zeros_like(x)\n",
    "        step[i] = h\n",
    "\n",
    "        # TODO: Use the central finite-difference formula\n",
    "        ## fp = ### complete code here\n",
    "        ## fm = ### complete code here\n",
    "        # grad[i] = ### complete code here\n",
    "\n",
    "    return grad\n",
    "\n",
    "\n",
    "def numerical_hessian(f, x, h=1e-4):\n",
    "    \"\"\"\n",
    "    Compute the numerical Hessian (matrix of second derivatives) of a 2D function \n",
    "    using central finite differences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : function\n",
    "        A Python function that takes two arguments, e.g. f(x, y) = sin(x) + cos(y).\n",
    "    x : array-like of shape (2,)\n",
    "        The point [x, y] at which to evaluate the Hessian.\n",
    "    h : float, optional\n",
    "        The finite difference step size (default is 1e-4).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    H : ndarray of shape (2, 2)\n",
    "        The numerical Hessian matrix:\n",
    "            [[‚àÇ¬≤f/‚àÇx¬≤, ‚àÇ¬≤f/‚àÇx‚àÇy],\n",
    "             [‚àÇ¬≤f/‚àÇy‚àÇx, ‚àÇ¬≤f/‚àÇy¬≤]]\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize empty Hessian matrix\n",
    "    n = len(x)\n",
    "    H = np.zeros((n, n))\n",
    "\n",
    "    # Double loop over indices (i, j)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            # Create small step vectors along the i-th and j-th directions\n",
    "            ei = np.zeros_like(x)\n",
    "            ej = np.zeros_like(x)\n",
    "            ei[i] = h\n",
    "            ej[j] = h\n",
    "\n",
    "            # TODO: Use the 4-point central difference formula for second derivatives:\n",
    "            # fpp = ### complete code here\n",
    "            # fpm = ### complete code here\n",
    "            # fmp = ### complete code here\n",
    "            # fmm = ### complete code here\n",
    "            #\n",
    "            # H[i, j] = ### complete code here\n",
    "\n",
    "    return H\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32dabd7-5222-4967-a200-050f727c97ab",
   "metadata": {},
   "source": [
    "‚úÖ **Your task:**\n",
    "- Complete the formulas in each loop according to the provided comments.  \n",
    "- Test your functions using `f2(x, y) = np.sin(x) + np.cos(y)` at a few points (e.g. `[2, 1]`).\n",
    "- Compare your numerical derivatives with the analytical ones to check accuracy.\n",
    "\n",
    "üí≠ **Hint:**  \n",
    "Remember that the function `f` takes *two separate arguments* (x and y),  \n",
    "so when calling it inside your loop you‚Äôll want to unpack the array `x` using `*x`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a295881a-01ea-4865-8580-fd9b60d1cb83",
   "metadata": {},
   "source": [
    "# ‚öõÔ∏è Step 7: Numerical Gradients from Quantum Chemistry Calculations\n",
    "\n",
    "So far, we‚Äôve used simple mathematical functions like $ f(x, y) = \\sin(x) + \\cos(y) $\n",
    "to test our numerical gradient and Hessian code.\n",
    "\n",
    "Let‚Äôs now connect this idea to a *real chemistry application*:\n",
    "computing the **potential energy surface** of a molecule using *ab initio* methods.\n",
    "\n",
    "In this example, we‚Äôll use the **PySCF** package to compute the total electronic energy of CO \n",
    "as a function of the C‚ÄìO bond length.\n",
    "\n",
    "We‚Äôll then see how we could use the same finite-difference formulas to estimate\n",
    "the **numerical gradient** (and eventually, the curvature) of that potential energy surface.\n",
    "\n",
    "## Installing pyscf\n",
    "You can install pyscf within this Jupypter session by running \n",
    "\n",
    "`!pip install pyscf`\n",
    "\n",
    "in the next cell.  You may also install pyscf into your local conda environment, and once you do that, you can skip this step in the future.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559da44-27e7-4e4e-8858-79d0b54dbc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyscf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca1147-7b49-417f-b53c-ca55b335d7fe",
   "metadata": {},
   "source": [
    "## Running PySCF energy calculation\n",
    "\n",
    "The next cell will set up a template for the geometry of a simple diatomic molecule, CO, where the $x$ value of the O atom is a variable.  Note that since this is a diatomic, the internal geometry of the molecule depends only on the scalar distance between the C and O atoms (the bond length), so the energy can be seen as a 1 dimensional function of the bond length.  Here, we will keep the $x$, $y$, and $z$ coordinates of the C atom fixed at the origin, and the $y$ and $z$ coordinates of the O atom will be similarly fixed at the origin.  Thus, the $x$ coordinate of the O atom alone determines the bond length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345ac9d6-1516-459b-b04d-c3835a54d807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyscf import gto, scf\n",
    "\n",
    "# Conversion factor: Angstrom ‚Üí Bohr (atomic units)\n",
    "ang_to_au = 1.88973\n",
    "\n",
    "# Template for the CO molecule\n",
    "mol_template = \"\"\"\n",
    "C 0 0 0\n",
    "O {} 0 0\n",
    "\"\"\"\n",
    "\n",
    "def compute_pyscf_energy(R_CO_angstrom):\n",
    "    \"\"\"\n",
    "    Compute the RHF total energy (in Hartrees) for CO at a given C‚ÄìO distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    R_CO_angstrom : float\n",
    "        The C‚ÄìO bond length in Angstroms.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    energy : float\n",
    "        The Hartree‚ÄìFock total energy (in Hartree atomic units).\n",
    "    \"\"\"\n",
    "    mol = gto.M(\n",
    "        atom=mol_template.format(R_CO_angstrom),\n",
    "        basis='cc-pvdz',\n",
    "        verbose=0,\n",
    "        spin=0\n",
    "    )\n",
    "    mf = scf.RHF(mol)\n",
    "    mf.kernel()\n",
    "    return mf.e_tot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ce6133-3c7e-4f52-bfc3-1bb5725a9b45",
   "metadata": {},
   "source": [
    "# ‚öôÔ∏è Step 1: Potential Energy Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5f73f-852d-4084-88b8-07baf0f63f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.01  # step size in Angstroms\n",
    "x = np.arange(0.8, 1.6, dx)\n",
    "\n",
    "hf_energies = [compute_pyscf_energy(R) for R in x]\n",
    "\n",
    "print(\"First few RHF energies (Hartree):\")\n",
    "print(hf_energies[:5])\n",
    "\n",
    "\n",
    "# plot of energies vs bond length\n",
    "plt.plot(x, hf_energies, label=\"RHF Energy\")\n",
    "plt.xlabel(\"Bond length (Angstroms)\")\n",
    "plt.ylabel(\"Energy (Hartree)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bfd722-a1d5-4b17-a189-cc9df0e7407b",
   "metadata": {},
   "source": [
    "‚úÖ **Question:**  \n",
    "What trend do you see in the energy values as the bond length changes?  \n",
    "Where roughly is the equilibrium bond length?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b407c40-0bb7-455e-ae7f-ebab41aad150",
   "metadata": {},
   "source": [
    "# üßÆ Step 2: Numerical Gradient from Energy Differences\n",
    "\n",
    "Now let‚Äôs numerically differentiate this energy function to estimate the force on the atoms, similar to what we did before but now we will call the `compute_pyscf_energy()` function!."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d121ee6c-95d4-4042-a85f-ccd25c13cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient_energy(f, R, h=0.01):\n",
    "    \"\"\"\n",
    "    Compute numerical derivative of energy with respect to bond length (force),\n",
    "    using a central finite difference formula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        A function that returns the molecular energy at a given bond length.\n",
    "    R : float\n",
    "        Current bond length in Angstroms.\n",
    "    h : float, optional\n",
    "        Step size in Angstroms (default 0.01 √Ö).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dE_dR : float\n",
    "        Numerical derivative of energy with respect to R (Hartree per Bohr)\n",
    "        \n",
    "        \n",
    "    Note: PySCF and our compute_pyscf_energy function will take the geometry information in Angstroms, \n",
    "    and will return the energy in atomic units.  It is good practice to keep the gradient and Hessian in a common unit\n",
    "    system, so we will want to convert the step length h from Angstroms to Bohr (where Bohr is the atomic unit of length)\n",
    "    for the gradient and Hessian calculations.\n",
    "    The conversion factor ang_to_au = 1.88973\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Use the central finite-difference formula\n",
    "    E_plus = ### complete code here\n",
    "    E_minus = ### complete code here\n",
    "\n",
    "    # get h in atomic units for the denominator of the finite difference calculation\n",
    "    ang_to_au = 1.88973\n",
    "    h_au = h * ang_to_au\n",
    "    dE_dR = ### complete code here\n",
    "    return dE_dR\n",
    "\n",
    "# Try evaluating at R = 1.2 √Ö\n",
    "R0 = 1.2\n",
    "grad_R = numerical_gradient_energy(compute_pyscf_energy, R0)\n",
    "print(f\"Numerical dE/dR at R = {R0:.2f} √Ö = {grad_R:.6f} Hartree/Bohr\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fcc35b-be12-464a-9fb4-ac5b87e7fe84",
   "metadata": {},
   "source": [
    "‚úÖ **Questions:**\n",
    "1. At what bond length does your numerical gradient change sign?  \n",
    "   (That‚Äôs the equilibrium bond length!)\n",
    "2. How many energy evaluations does it take to compute this gradient?\n",
    "3. What would happen if you needed to compute **gradients for all atomic coordinates** in a polyatomic molecule?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d46737-04b7-464b-ab64-c4961776936c",
   "metadata": {},
   "source": [
    "# üßÆ Step 8: 1D Newton‚ÄìRaphson Geometry Optimization of CO\n",
    "\n",
    "Now that we can compute the molecular energy $ E(R) $ and its numerical derivative \n",
    "$ \\frac{dE}{dR} $, we can perform a simple **geometry optimization**.\n",
    "\n",
    "For a diatomic molecule, this means finding the bond length $ R $ that minimizes the total energy.\n",
    "\n",
    "We‚Äôll use the **1D Newton‚ÄìRaphson method**, applied to the derivative of the potential energy:\n",
    "$\n",
    "R_{n+1} = R_n - \\frac{(dE/dR)}{(d^2E/dR^2)}\n",
    "$\n",
    "\n",
    "Since we don‚Äôt have an analytic expression for $ E(R) $, we‚Äôll also approximate \n",
    "the second derivative (curvature) numerically using finite differences.\n",
    "\n",
    "You will need to complete the second derivative function, but the Newton-Raphson optimization function that calls these functions is already complete for you below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf254a0-2793-4209-9957-09b4f001378a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_second_derivative(f, R, h=0.01):\n",
    "    \"\"\"\n",
    "    Compute the numerical second derivative of energy with respect to bond length\n",
    "    using the central finite-difference formula.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        Function returning molecular energy at a given bond length.\n",
    "    R : float\n",
    "        Current bond length (Angstroms).\n",
    "    h : float, optional\n",
    "        Step size for finite difference (default 0.01 √Ö).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    d2E_dR2 : float\n",
    "        Numerical second derivative (Hartree per Bohr¬≤).\n",
    "\n",
    "    Note Again: PySCF and our compute_pyscf_energy function will take the geometry information in Angstroms, \n",
    "    and will return the energy in atomic units.  It is good practice to keep the gradient and Hessian in a common unit\n",
    "    system, so we will want to convert the step length h from Angstroms to Bohr (where Bohr is the atomic unit of length)\n",
    "    for the gradient and Hessian calculations.\n",
    "    The conversion factor ang_to_au = 1.88973\n",
    "    \"\"\"\n",
    "    E_plus = ## complete code here\n",
    "    E_minus = ## complete code here\n",
    "    E0 = ## complete code here\n",
    "    \n",
    "    # get h in atomic units for the denominator of the finite difference calculation\n",
    "    ang_to_au = 1.88973\n",
    "    h_au = h * ang_to_au\n",
    "    \n",
    "    d2E_dR2 = ## complete code here\n",
    "    return d2E_dR2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517ce715-5e11-41ab-8ab5-601dbb77766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_optimize_bond(f, R0, tol=1e-5, max_iter=10, h=0.01):\n",
    "    \"\"\"\n",
    "    Perform a 1D Newton‚ÄìRaphson optimization of a bond length.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        Function returning molecular energy at a given bond length.\n",
    "    R0 : float\n",
    "        Initial bond length (Angstroms).\n",
    "    tol : float\n",
    "        Convergence tolerance on bond length change (√Ö).\n",
    "    max_iter : int\n",
    "        Maximum number of iterations.\n",
    "    h : float\n",
    "        Step size for numerical derivatives.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    R_opt : float\n",
    "        Optimized bond length (√Ö).\n",
    "    E_opt : float\n",
    "        Energy at optimized geometry (Hartree).\n",
    "\n",
    "    Note: PySCF and our compute_pyscf_energy function will take the geometry information in Angstroms, \n",
    "    and will return the energy in atomic units.  It is good practice to keep the gradient and Hessian in a common unit\n",
    "    system, so we will want to convert the step length h from Angstroms to Bohr (where Bohr is the atomic unit of length)\n",
    "    for the gradient and Hessian calculations.  This means tht when we compute step = -grad / hess, this step will be in Bohr.\n",
    "    We need to convert this step back to Angstroms before adding it to R, this time using the inverse of the conversion from Angstromg -> Bohr\n",
    "    ang_to_au = 1.88973 -> au_to_ang = 1/1.88973\n",
    "    \"\"\"\n",
    "    # conversion from Bohr to Angstroms\n",
    "    au_to_ang = 1/1.88973\n",
    "    R = R0\n",
    "    print(f\"Starting optimization from R = {R0:.3f} √Ö\")\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        grad = numerical_gradient_energy(f, R, h)\n",
    "        hess = numerical_second_derivative(f, R, h)\n",
    "\n",
    "        step = -grad / hess\n",
    "        step_Angs = step * au_to_ang\n",
    "        R_new = R + step\n",
    "\n",
    "        print(f\"Iter {i:2d}: R = {R:.4f} √Ö, E = {f(R):.6f} Ha, dE/dR = {grad:.3e}, step = {step_Angs:.3e}\")\n",
    "\n",
    "        if abs(step) < tol:\n",
    "            print(f\"\\n‚úÖ Converged to R = {R_new:.4f} √Ö, E = {f(R_new):.6f} Ha\")\n",
    "            return R_new, f(R_new)\n",
    "\n",
    "        R = R_new\n",
    "\n",
    "    print(\"\\n‚ö†Ô∏è Did not converge within max_iter\")\n",
    "    return R, f(R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216451bf-6ede-487c-9911-8706b72b9b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_start = 1.4  # initial guess in √Ö\n",
    "R_opt, E_opt = newton_optimize_bond(compute_pyscf_energy, R_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc0ad1-82db-4b31-8f55-1b677f60bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "‚úÖ **Questions to Explore**\n",
    "1. How many iterations did it take to converge?\n",
    "2. Try changing the initial guess (`R_start = 0.8` or `1.8`).  \n",
    "   Does Newton‚ÄìRaphson still converge to the same bond length?\n",
    "3. Why does the second derivative (the curvature) need to be positive at the minimum?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4226a2c-4435-4caf-b012-fe354a7c640a",
   "metadata": {},
   "source": [
    "# üå± Toward Quasi-Newton (BFGS)\n",
    "\n",
    "Quasi-Newton methods like BFGS avoid explicit construction of the Hessian matrix, and instead approximate the Hessian information using gradient information.  One common quasi-Newton method is called the BFGS algorithm, which you can read about [here](https://towardsdatascience.com/bfgs-in-a-nutshell-an-introduction-to-quasi-newton-methods-21b0e13ee504/) and [here](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm).\n",
    "\n",
    "**Next Steps**\n",
    "Try your hand at adding a function `BFGS_Update` that will take in position and gradient information and return an approximate Hessian matrix following the BFGS algorithm.  Some questions to consider include:\n",
    "\n",
    "1. How many positions vectors are needed (do you just need the current position vector, the current and one past position vectors, more?)\n",
    "2. How many gradient vectors are needed (do you just need the current gradient vector, the current and one past gradient vectors, more?)\n",
    "3. Are you directly building an approximation to the Hessian, or to the inverse of the Hessian?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1da6f-bc70-4843-b517-d02727025bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
